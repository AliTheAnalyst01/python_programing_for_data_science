{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Staff data frame has the following columns: \n",
      "['name', 'city', 'date_of_birth', 'start_date', 'salary', 'department']\n",
      "\n",
      "               name             city date_of_birth  start_date   salary  \\\n",
      "0          John Doe      Houston, TX    1998-11-04  2018-08-11  $65,000   \n",
      "1          Jane Doe     San Jose, CA    1995-08-05  2017-08-24  $70,000   \n",
      "2        Matt smith       Dallas, TX    1996-11-25  2020-04-16  $58,500   \n",
      "3     Ashley Harris        Miami, FL    1995-01-08  2021-02-11  $49,500   \n",
      "4  Jonathan targett  Santa Clara, CA    1998-08-14  2020-09-01  $62,000   \n",
      "5         Hale Cole      Atlanta, GA    2000-10-24  2021-10-20  $54,500   \n",
      "\n",
      "        department  \n",
      "0       Accounting  \n",
      "1    Field Quality  \n",
      "2  human resources  \n",
      "3       accounting  \n",
      "4    field quality  \n",
      "5      engineering  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "staff = pd.read_csv(\"staff.csv\")\n",
    "\n",
    "print(f\"\\nStaff data frame has the following columns: \\n{list(staff.columns)}\\n\")\n",
    "\n",
    "print(staff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    J\n",
      "1    J\n",
      "2    M\n",
      "3    A\n",
      "4    J\n",
      "5    H\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(staff[\"name\"].str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Joh\n",
      "1    Jan\n",
      "2    Mat\n",
      "3    Ash\n",
      "4    Jon\n",
      "5    Hal\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "staff = pd.read_csv(\"staff.csv\")\n",
    "\n",
    "print(staff[\"name\"].str[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        onDe\n",
      "1        aeDe\n",
      "2       atsih\n",
      "3      slyHri\n",
      "4    oahntret\n",
      "5        aeCl\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(staff[\"name\"].str[1::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting\n",
    "In some cases, strings contain several pieces of information so we might need to split a string in order to access one piece of information.\n",
    "\n",
    "In staff, the name column contains both the first and last names. We can easily extract the first or last names from the name column by using the split function.\n",
    "\n",
    "The Pandas split function is available under the str accessor. It splits a string at the position of the given character and then returns a list of all parts.\n",
    "\n",
    "Let’s look at a simple example first. The following code snippet splits the name column at the space character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            [John, Doe]\n",
      "1            [Jane, Doe]\n",
      "2          [Matt, smith]\n",
      "3       [Ashley, Harris]\n",
      "4    [Jonathan, targett]\n",
      "5           [Hale, Cole]\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(staff[\"name\"].str.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name last_name\n",
      "0          John Doe       Doe\n",
      "1          Jane Doe       Doe\n",
      "2        Matt smith     smith\n",
      "3     Ashley Harris    Harris\n",
      "4  Jonathan targett   targett\n",
      "5         Hale Cole      Cole\n"
     ]
    }
   ],
   "source": [
    "\n",
    "staff[\"last_name\"] = staff[\"name\"].str.split(\" \", expand=True)[1]\n",
    "\n",
    "print(staff[[\"name\",\"last_name\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining\n",
    "Just like we split strings, we can combine multiple strings into a single one.\n",
    "\n",
    "The + operator can be used to combine strings. Let’s review a quick example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               John Doe - Accounting\n",
      "1            Jane Doe - Field Quality\n",
      "2        Matt smith - human resources\n",
      "3          Ashley Harris - accounting\n",
      "4    Jonathan targett - field quality\n",
      "5             Hale Cole - engineering\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(staff[\"name\"] + \" - \" + staff[\"department\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper and lower case\n",
    "Python is case-sensitive. This means that we need to have the strings in standard format in order to perform analysis on them. Thankfully, it’s quite simple to change a string’s case in Pandas.\n",
    "\n",
    "The names in our staff have both upper and lower case letters. Let’s convert all of them to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name        name_lower\n",
      "0          John Doe          john doe\n",
      "1          Jane Doe          jane doe\n",
      "2        Matt smith        matt smith\n",
      "3     Ashley Harris     ashley harris\n",
      "4  Jonathan targett  jonathan targett\n",
      "5         Hale Cole         hale cole\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "staff[\"name_lower\"] = staff[\"name\"].str.lower()\n",
    "\n",
    "print(staff[[\"name\",\"name_lower\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCOUNTING\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(staff[\"department\"][0].upper())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The replace function\n",
    "The Pandas library provides highly flexible ways to manipulate strings. One of them is the replace function, under the str accessor. It can be used to replace a character or a sequence of characters in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Houston- TX\n",
      "1       San Jose- CA\n",
      "2         Dallas- TX\n",
      "3          Miami- FL\n",
      "4    Santa Clara- CA\n",
      "5        Atlanta- GA\n",
      "Name: city, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(staff[\"city\"].str.replace(\",\", \"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Texas\n",
      "1    California\n",
      "2         Texas\n",
      "3       Florida\n",
      "4    California\n",
      "5       Georgia\n",
      "Name: state, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a state colum\n",
    "staff[\"state\"] = staff[\"city\"].str[-2:]\n",
    "\n",
    "# Replace state abbreviations with actual state names\n",
    "staff[\"state\"].replace(\n",
    "    {\"TX\": \"Texas\", \"CA\": \"California\", \"FL\": \"Florida\", \"GA\": \"Georgia\"},\n",
    "    inplace = True\n",
    ")\n",
    "\n",
    "print(staff[\"state\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine multiple string manipulation operations into a single chained operation. For instance, we can extract the state part from the city column and convert it to lowercase letters in a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     tx\n",
      "1     ca\n",
      "2     tx\n",
      "3     fl\n",
      "4     ca\n",
      "5     ga\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "staff = pd.read_csv(\"staff.csv\")\n",
    "\n",
    "print(staff[\"city\"].str.split(\",\", expand=True)[1].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         accounting\n",
      "1            quality\n",
      "2    human resources\n",
      "3         accounting\n",
      "4            quality\n",
      "5        engineering\n",
      "Name: department, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(staff[\"department\"].str.lower().replace(\"field quality\",\"quality\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    2020\n",
      "4    2020\n",
      "Name: start_date, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(staff.query(\"name > 'John Doe'\").start_date.str[:4].astype(\"int\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date and time data types\n",
    "We can express dates and times in three main forms:\n",
    "\n",
    "A specific date or time (2021-12-10, 2021-11-25 14:59:00)\n",
    "A fixed interval (hour, week, month).\n",
    "A duration (3 weeks, 4 hours and 30 minutes).\n",
    "\n",
    "The Pandas library has several functions and methods to handle these different forms efficiently and easily. It’s important to use appropriate data types for date and time values. Otherwise, we won’t be able to use Pandas functions for dates and times.\n",
    "\n",
    "The datetime64[ns] data type can be used to express date and time values. The values that have datetime64[ns]data type are calledTimestamp. A Timestampcontains both date and time information. We can convert a string representing a date to a Timestamp by using theto_datetime` constructor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 days 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "first_date = pd.to_datetime(\"2021-10-10\")\n",
    "second_date = pd.to_datetime(\"2021-10-02\")\n",
    "\n",
    "diff = first_date - second_date\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9131 days +00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "first_date = pd.to_datetime(\"1998-07-28\")\n",
    "second_date = pd.to_datetime(\"2023-07-28\")\n",
    "\n",
    "diff = first_date - second_date\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                     object\n",
      "city                     object\n",
      "date_of_birth    datetime64[ns]\n",
      "start_date       datetime64[ns]\n",
      "salary                   object\n",
      "department               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "staff = pd.read_csv(\"staff.csv\")\n",
    "\n",
    "staff = staff.astype({\n",
    "    \"date_of_birth\": \"datetime64[ns]\",\n",
    "    \"start_date\": \"datetime64[ns]\",\n",
    "})\n",
    "\n",
    "print(staff.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates include lots of information\n",
    "A Timestamp object contains multiple pieces of information, such as year, month, week, day of the week, hour, minute, and so on. We have many options to express an instance in time. In some cases, it’s enough to only specify the date. Some tasks require precision in minutes or seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The year part is 2021\n",
      "The month part is 10\n",
      "The week number part is 40\n",
      "The day part is 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mydate = pd.to_datetime(\"2021-10-10\")\n",
    "\n",
    "print(f\"The year part is {mydate.year}\")\n",
    "print(f\"The month part is {mydate.month}\")\n",
    "print(f\"The week number part is {mydate.week}\")\n",
    "print(f\"The day part is {mydate.day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hour part of mydate is 14\n",
      "The minute part of mydate is 30\n",
      "The second part of mydate is 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mydate = pd.to_datetime(\"2021-10-10 14:30:00\")\n",
    "\n",
    "print(f\"The hour part of mydate is {mydate.hour}\")\n",
    "print(f\"The minute part of mydate is {mydate.minute}\")\n",
    "print(f\"The second part of mydate is {mydate.second}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date part is 2021-12-21\n",
      "The day of week is 1\n",
      "The name of the month is December\n",
      "The name of the day is Tuesday\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mydate = pd.to_datetime(\"2021-12-21 00:00:00\")\n",
    "\n",
    "print(f\"The date part is {mydate.date()}\")\n",
    "print(f\"The day of week is {mydate.weekday()}\")\n",
    "print(f\"The name of the month is {mydate.month_name()}\")\n",
    "print(f\"The name of the day is {mydate.day_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  start_date  start_month\n",
      "0 2018-08-11            8\n",
      "1 2017-08-24            8\n",
      "2 2020-04-16            4\n",
      "3 2021-02-11            2\n",
      "4 2020-09-01            9\n",
      "5 2021-10-20           10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read DataFrame\n",
    "staff = pd.read_csv(\"staff.csv\")\n",
    "\n",
    "# change the data type of date columns\n",
    "staff = staff.astype({\n",
    "    \"date_of_birth\": \"datetime64[ns]\",\n",
    "    \"start_date\": \"datetime64[ns]\",\n",
    "})\n",
    "\n",
    "# create start_month column\n",
    "staff[\"start_month\"] = staff[\"start_date\"].dt.month\n",
    "\n",
    "print(staff[[\"start_date\",\"start_month\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods under the dt accessor\n",
    "We can get the year and dayparts using the year and day in a similar way. Some other methods available through the dt accessor are:\n",
    "\n",
    "weekday\n",
    "hour\n",
    "minute\n",
    "second\n",
    "week (deprecated since version 1.1.0)\n",
    "weekofyear (deprecated since version 1.1.0)\n",
    "In Pandas version 1.1.0 or higher, isocalendar is a highly useful alternative to week and weekofyear. When applied to a column, it returns a DataFrame that contains the year, calendar week, and day of week information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  week  day\n",
       "0  2018    32    6\n",
       "1  2017    34    4\n",
       "2  2020    16    4\n",
       "3  2021     6    4\n",
       "4  2020    36    2\n",
       "5  2021    42    3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staff[\"start_date\"].dt.isocalendar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DateOffset function\n",
    "One Pandas function we can use to add or subtract dates and times is DateOffset. It can be used with both dates and times. We only need to specify the unit and quantity to be added or subtracted. Consider a case where we want to give a raise to our employees one year after they’re hired. In the staff, we can create a column called raise_date by adding one year to the start_date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  start_date raise_date\n",
      "0 2018-08-11 2019-08-11\n",
      "1 2017-08-24 2018-08-24\n",
      "2 2020-04-16 2021-04-16\n",
      "3 2021-02-11 2022-02-11\n",
      "4 2020-09-01 2021-09-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create the DataFrame\n",
    "staff = pd.read_csv(\"staff.csv\")\n",
    "\n",
    "# change the date type\n",
    "staff = staff.astype({\n",
    "    \"date_of_birth\": \"datetime64[ns]\",\n",
    "    \"start_date\": \"datetime64[ns]\"\n",
    "})\n",
    "\n",
    "# create raise_date column\n",
    "staff[\"raise_date\"] = staff[\"start_date\"] + pd.DateOffset(years=1)\n",
    "\n",
    "print(staff[[\"start_date\",\"raise_date\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2019-02-11\n",
       "1   2018-02-24\n",
       "2   2020-10-16\n",
       "3   2021-08-11\n",
       "4   2021-03-01\n",
       "5   2022-04-20\n",
       "Name: start_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staff[\"start_date\"] + pd.DateOffset(months=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first method\n",
      "2021-12-14 14:50:00\n",
      "\n",
      "The second method\n",
      "2021-12-14 14:50:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mytime = pd.Timestamp(\"2021-12-14 16:50:00\")\n",
    "\n",
    "print(\"The first method\")\n",
    "print(mytime + pd.DateOffset(hours=-2))\n",
    "\n",
    "print(\"\\nThe second method\")\n",
    "print(mytime - pd.DateOffset(hours=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2018-11-03\n",
      "1   2017-11-16\n",
      "2   2020-07-09\n",
      "3   2021-05-06\n",
      "4   2020-11-24\n",
      "5   2022-01-12\n",
      "Name: start_date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create the DataFrame\n",
    "staff = pd.read_csv(\"staff.csv\")\n",
    "\n",
    "# change the date type\n",
    "staff = staff.astype({\n",
    "    \"date_of_birth\": \"datetime64[ns]\",\n",
    "    \"start_date\": \"datetime64[ns]\"\n",
    "})\n",
    "\n",
    "# add 12 weeks\n",
    "print(staff[\"start_date\"] + pd.Timedelta(value=12, unit=\"W\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2018-11-03\n",
      "1   2017-11-16\n",
      "2   2020-07-09\n",
      "3   2021-05-06\n",
      "4   2020-11-24\n",
      "5   2022-01-12\n",
      "Name: start_date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create the DataFrame\n",
    "staff = pd.read_csv(\"staff.csv\")\n",
    "\n",
    "# change the date type\n",
    "staff = staff.astype({\n",
    "    \"date_of_birth\": \"datetime64[ns]\",\n",
    "    \"start_date\": \"datetime64[ns]\"\n",
    "})\n",
    "\n",
    "# add 12 weeks\n",
    "print(staff[\"start_date\"] + pd.Timedelta(\"12 W\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C     D  E\n",
      "0  1.0  2.4  NaN  11.5  1\n",
      "2  3.0  5.1  zoo   6.2  3\n",
      "4  7.0  2.6  NaN   8.7  5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"A\": [1, 2, 3, np.nan, 7],\n",
    "    \"B\": [2.4, np.nan, 5.1, np.nan, 2.6],\n",
    "    \"C\": [np.nan, \"foo\",\"zoo\",\"bar\", np.nan],\n",
    "    \"D\": [11.5, np.nan, 6.2, 21.1, 8.7],\n",
    "    \"E\": [1, 2, 3, 4, 5]\n",
    "})\n",
    "\n",
    "# Drop rows that have less than 4 non-missing values\n",
    "df.dropna(thresh=4, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.00\n",
      "1    2.00\n",
      "2    3.00\n",
      "3    3.25\n",
      "4    7.00\n",
      "Name: A, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"A\": [1, 2, 3, np.nan, 7],\n",
    "    \"B\": [2.4, np.nan, 5.1, np.nan, 2.6],\n",
    "    \"C\": [np.nan, \"foo\",\"zoo\",\"bar\", np.nan],\n",
    "    \"D\": [11.5, np.nan, 6.2, 21.1, 8.7],\n",
    "    \"E\": [1, 2, 3, 4, 5]\n",
    "})\n",
    "\n",
    "print(df[\"A\"].fillna(value = df[\"A\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C       D  E\n",
      "0  1.00  2.4  NaN  11.500  1\n",
      "1  2.00  NaN  foo  11.875  2\n",
      "2  3.00  5.1  zoo   6.200  3\n",
      "3  3.25  NaN  bar  21.100  4\n",
      "4  7.00  2.6  NaN   8.700  5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"A\": [1, 2, 3, np.nan, 7],\n",
    "    \"B\": [2.4, np.nan, 5.1, np.nan, 2.6],\n",
    "    \"C\": [np.nan, \"foo\",\"zoo\",\"bar\", np.nan],\n",
    "    \"D\": [11.5, np.nan, 6.2, 21.1, 8.7],\n",
    "    \"E\": [1, 2, 3, 4, 5]\n",
    "})\n",
    "\n",
    "# find the replacement values\n",
    "value_a = df[\"A\"].mean()\n",
    "value_d = df[\"D\"].mean()\n",
    "\n",
    "# replace the missing values\n",
    "print(df.fillna({\"A\": value_a, \"D\": value_d}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reiterate, determining the replacement value depends on the characteristics of the data. For instance, if our data consists of the daily stock prices, filling a missing value with the previous or next value is more optimal than using the average. This is a commonly used approach in time-series data. The fillna function performs this operation easily with the method parameter.\n",
    "\n",
    "method = \"bfill\": Replace missing values backward, which means that a missing value is replaced by the value that comes after it.\n",
    "\n",
    "method = \"ffill\": Replace missing values forward, which means that a missing value is replaced by the value that comes before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling backward\n",
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    7.0\n",
      "4    7.0\n",
      "Name: A, dtype: float64\n",
      "\n",
      "Filling forward\n",
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    7.0\n",
      "Name: A, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"A\": [1, 2, 3, np.nan, 7],\n",
    "    \"B\": [2.4, np.nan, 5.1, np.nan, 2.6],\n",
    "    \"C\": [np.nan, \"foo\",\"zoo\",\"bar\", np.nan],\n",
    "    \"D\": [11.5, np.nan, 6.2, 21.1, 8.7],\n",
    "    \"E\": [1, 2, 3, 4, 5]\n",
    "})\n",
    "\n",
    "print(\"Filling backward\")\n",
    "print(df[\"A\"].fillna(method=\"bfill\"))\n",
    "\n",
    "print(\"\\nFilling forward\")\n",
    "print(df[\"A\"].fillna(method=\"ffill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# grocery = pd.read_csv(\"grocery.csv\")\n",
    "\n",
    "# # Creating the week column\n",
    "# grocery[\"sales_date\"] = grocery[\"sales_date\"].astype(\"datetime64[ns]\")\n",
    "# grocery[\"week\"] = grocery[\"sales_date\"].dt.week\n",
    "\n",
    "# # Creating the pivot table\n",
    "# print(\n",
    "#   pd.pivot_table(\n",
    "#     data = grocery, \n",
    "#     values = \"price\", \n",
    "#     index = \"week\", \n",
    "#     columns = \"product_group\",\n",
    "#     aggfunc = [\"mean\",\"std\"]\n",
    "#   )\n",
    "#  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cut function\n",
    "Both the cut and qcut functions convert columns with continuous values to categorical columns, but they apply different techniques. The cut function divides the entire value range into intervals of the same size, called bins. The range covered by each bin will be the same. If the minimum value is 0 and the maximum value is 10 and we want to divide the values into four groups (bins). The bins will be created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    medium\n",
      "1     small\n",
      "2     small\n",
      "3     large\n",
      "4    medium\n",
      "5     large\n",
      "dtype: category\n",
      "Categories (3, object): ['small' < 'medium' < 'large']\n",
      "\n",
      "\n",
      "small     2\n",
      "medium    2\n",
      "large     2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a Series with values between 0 and 10\n",
    "A = pd.Series([5, 0, 2, 8, 4, 10])\n",
    "\n",
    "# cut function\n",
    "A_binned = pd.cut(A, bins=[-1, 3, 6, 10], labels=[\"small\",\"medium\",\"large\"])\n",
    "\n",
    "print(A_binned)\n",
    "print(\"\\n\")\n",
    "print(A_binned.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The qcut function\n",
    "The cut function divides the entire values range into bins of equal sizes. With the qcut function, the focus is on the number of values that fall into the bins. The qcut function groups the values into bins so that there is approximately the same number of values in each bin. The upper and lower bounds are adjusted accordingly. The following block of code demonstrates how the qcut function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.999, 5.5]    6\n",
      "(5.5, 8.25]     3\n",
      "(8.25, 14.0]    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "A = pd.Series([1, 4, 2, 10, 5, 6, 8])\n",
    "\n",
    "# The qcut function\n",
    "A = pd.Series([1, 4, 2, 3, 10, 5, 6, 8, 7, 5, 9, 14])\n",
    "\n",
    "A_binned = pd.qcut(A, q=[0, 0.50, 0.75, 1])\n",
    "\n",
    "print(A_binned.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.999, 4.667]    4\n",
      "(4.667, 6.333]    4\n",
      "(6.333, 10.0]     4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "A = pd.Series([1, 4, 2, 10, 5, 6, 8])\n",
    "\n",
    "# The qcut function\n",
    "A = pd.Series([1, 4, 2, 10, 5, 6, 8, 7, 5, 3, 5, 9])\n",
    "\n",
    "A_binned = pd.qcut(A, q=3)\n",
    "\n",
    "print(A_binned.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining DataFrames\n",
    "We sometimes need to collect data from different resources and combine them into a single DataFrame. How we approach this task depends on the characteristic of the data and the way it’s represented.\n",
    "\n",
    "One option is to combine them by stacking them side-by-side or on top of each other. We can imagine building a brick wall. One wall is made up of multiple bricks placed side-by-side and on top of one another. The concat function can be used for this task. Let’s go over some examples to learn how this function is used. Suppose we have the following DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B  C\n",
      "0  1  11  a\n",
      "1  5   6  d\n",
      "2  3   9  f\n",
      "3  2   6  b\n",
      "0  2  14  b\n",
      "1  4   9  b\n",
      "2  1   5  j\n",
      "3  7   8  a\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\"A\":[1,5,3,2], \"B\":[11,6,9,6], \"C\":[\"a\",\"d\",\"f\",\"b\"]})\n",
    "\n",
    "df2 = pd.DataFrame({\"A\":[2,4,1,7], \"B\":[14,9,5,8], \"C\":[\"b\",\"b\",\"j\",\"a\"]})\n",
    "\n",
    "df_combined = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B    C    D\n",
      "0  1  11    a  NaN\n",
      "1  5   6    d  NaN\n",
      "2  3   9    f  NaN\n",
      "3  2   6    b  NaN\n",
      "4  2  14  NaN    b\n",
      "5  4   9  NaN    b\n",
      "6  1   5  NaN    j\n",
      "7  7   8  NaN    a\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\"A\":[1,5,3,2], \"B\":[11,6,9,6], \"C\":[\"a\",\"d\",\"f\",\"b\"]})\n",
    "\n",
    "df2 = pd.DataFrame({\"A\":[2,4,1,7], \"B\":[14,9,5,8], \"D\":[\"b\",\"b\",\"j\",\"a\"]})\n",
    "\n",
    "df_combined = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B  C  A   B  D\n",
      "0  1  11  a  2  14  b\n",
      "1  5   6  d  4   9  b\n",
      "2  3   9  f  1   5  j\n",
      "3  2   6  b  7   8  a\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\"A\":[1,5,3,2], \"B\":[11,6,9,6], \"C\":[\"a\",\"d\",\"f\",\"b\"]})\n",
    "\n",
    "df2 = pd.DataFrame({\"A\":[2,4,1,7], \"B\":[14,9,5,8], \"D\":[\"b\",\"b\",\"j\",\"a\"]})\n",
    "\n",
    "df_combined = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_code  weight  price  sales_date  sales_qty\n",
      "0          1001     125   10.5  2021-12-10        8.0\n",
      "1          1002     200   24.5  2021-12-10       14.0\n",
      "2          1003     100    9.9  2021-12-10       22.0\n",
      "3          1004     400   34.5         NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create product and sales DataFrames\n",
    "product = pd.DataFrame({\n",
    "  \"product_code\": [1001, 1002, 1003, 1004],\n",
    "  \"weight\": [125, 200, 100, 400],\n",
    "  \"price\": [10.5, 24.5, 9.9, 34.5]\n",
    "})\n",
    "\n",
    "sales = pd.DataFrame({\n",
    "  \"product_code\": [1001, 1002, 1003, 1007],\n",
    "  \"sales_date\": [\"2021-12-10\"] * 4,\n",
    "  \"sales_qty\": [8, 14, 22, 7]\n",
    "})\n",
    "\n",
    "# merge DataFrames\n",
    "merged_df = product.merge(sales, how=\"left\", on=\"product_code\")\n",
    "\n",
    "print(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
